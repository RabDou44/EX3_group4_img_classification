{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adam\\AppData\\Local\\Temp\\ipykernel_18736\\1802083502.py:9: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare transformers and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformTrainAug = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(28, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "transformTest = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "trainData = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transformTest)\n",
    "trainLoader = torch.utils.data.DataLoader(trainData, batch_size=64,shuffle=True, num_workers=2)\n",
    "\n",
    "trainDataAug =  torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transformTrainAug)\n",
    "trainLoaderAug = torch.utils.data.DataLoader(trainDataAug, batch_size=64,shuffle=True, num_workers=2)\n",
    "\n",
    "testData = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transformTest)\n",
    "testLoader = torch.utils.data.DataLoader(testData, batch_size=64, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(nnModel, trainLoader, optimizerMethod=optim.SGD, lossFunction=nn.CrossEntropyLoss(), lRate = 0.005, n_epochs = 10):\n",
    "    optimizer = optimizerMethod(nnModel.parameters(), lRate, momentum=0.5)\n",
    "\n",
    "    start = time.time()\n",
    "    for epch in range(n_epochs): \n",
    "        # before each epoch DataLoader reshuffles \n",
    "        for idx,dataBatch in enumerate(trainLoader):\n",
    "            input, labels = dataBatch\n",
    "            \n",
    "            # zeroing out the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            output = nnModel(input)\n",
    "            loss = lossFunction(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                print(f\"Loss: {loss.item():.3f}  Epoch:{epch} Iteration:{idx}\")\n",
    "    \n",
    "    end = time.time()\n",
    "    return nnModel, end - start\n",
    "\n",
    "def evalNN(nnModel, testLoader):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data in testLoader:\n",
    "            images, labels = data\n",
    "            outputs = nnModel(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_true += labels.cpu().numpy().tolist()\n",
    "            y_pred += predicted.cpu().numpy().tolist()\n",
    "\n",
    "        return y_true, y_pred\n",
    "    \n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool2(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Lenet without data augemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.298  Epoch:0 Iteration:0\n",
      "Loss: 2.299  Epoch:0 Iteration:100\n",
      "Loss: 2.294  Epoch:0 Iteration:200\n",
      "Loss: 2.280  Epoch:0 Iteration:300\n",
      "Loss: 2.271  Epoch:0 Iteration:400\n",
      "Loss: 2.221  Epoch:0 Iteration:500\n",
      "Loss: 2.106  Epoch:0 Iteration:600\n",
      "Loss: 1.835  Epoch:0 Iteration:700\n",
      "Loss: 1.286  Epoch:0 Iteration:800\n",
      "Loss: 0.936  Epoch:0 Iteration:900\n",
      "Loss: 0.640  Epoch:1 Iteration:0\n",
      "Loss: 0.703  Epoch:1 Iteration:100\n",
      "Loss: 0.577  Epoch:1 Iteration:200\n",
      "Loss: 0.586  Epoch:1 Iteration:300\n",
      "Loss: 0.889  Epoch:1 Iteration:400\n",
      "Loss: 0.760  Epoch:1 Iteration:500\n",
      "Loss: 0.542  Epoch:1 Iteration:600\n",
      "Loss: 0.468  Epoch:1 Iteration:700\n",
      "Loss: 0.492  Epoch:1 Iteration:800\n",
      "Loss: 0.421  Epoch:1 Iteration:900\n",
      "Loss: 0.480  Epoch:2 Iteration:0\n",
      "Loss: 0.484  Epoch:2 Iteration:100\n",
      "Loss: 0.433  Epoch:2 Iteration:200\n",
      "Loss: 0.580  Epoch:2 Iteration:300\n",
      "Loss: 0.509  Epoch:2 Iteration:400\n",
      "Loss: 0.483  Epoch:2 Iteration:500\n",
      "Loss: 0.381  Epoch:2 Iteration:600\n",
      "Loss: 0.514  Epoch:2 Iteration:700\n",
      "Loss: 0.525  Epoch:2 Iteration:800\n",
      "Loss: 0.575  Epoch:2 Iteration:900\n",
      "Loss: 0.622  Epoch:3 Iteration:0\n",
      "Loss: 0.434  Epoch:3 Iteration:100\n",
      "Loss: 0.680  Epoch:3 Iteration:200\n",
      "Loss: 0.336  Epoch:3 Iteration:300\n",
      "Loss: 0.468  Epoch:3 Iteration:400\n",
      "Loss: 0.517  Epoch:3 Iteration:500\n",
      "Loss: 0.424  Epoch:3 Iteration:600\n",
      "Loss: 0.371  Epoch:3 Iteration:700\n",
      "Loss: 0.554  Epoch:3 Iteration:800\n",
      "Loss: 0.539  Epoch:3 Iteration:900\n",
      "Loss: 0.632  Epoch:4 Iteration:0\n",
      "Loss: 0.381  Epoch:4 Iteration:100\n",
      "Loss: 0.558  Epoch:4 Iteration:200\n",
      "Loss: 0.522  Epoch:4 Iteration:300\n",
      "Loss: 0.480  Epoch:4 Iteration:400\n",
      "Loss: 0.510  Epoch:4 Iteration:500\n",
      "Loss: 0.380  Epoch:4 Iteration:600\n",
      "Loss: 0.493  Epoch:4 Iteration:700\n",
      "Loss: 0.442  Epoch:4 Iteration:800\n",
      "Loss: 0.518  Epoch:4 Iteration:900\n",
      "Loss: 0.476  Epoch:5 Iteration:0\n",
      "Loss: 0.261  Epoch:5 Iteration:100\n",
      "Loss: 0.506  Epoch:5 Iteration:200\n",
      "Loss: 0.268  Epoch:5 Iteration:300\n",
      "Loss: 0.590  Epoch:5 Iteration:400\n",
      "Loss: 0.446  Epoch:5 Iteration:500\n",
      "Loss: 0.440  Epoch:5 Iteration:600\n",
      "Loss: 0.349  Epoch:5 Iteration:700\n",
      "Loss: 0.171  Epoch:5 Iteration:800\n",
      "Loss: 0.553  Epoch:5 Iteration:900\n",
      "Loss: 0.381  Epoch:6 Iteration:0\n",
      "Loss: 0.308  Epoch:6 Iteration:100\n",
      "Loss: 0.318  Epoch:6 Iteration:200\n",
      "Loss: 0.233  Epoch:6 Iteration:300\n",
      "Loss: 0.559  Epoch:6 Iteration:400\n",
      "Loss: 0.317  Epoch:6 Iteration:500\n",
      "Loss: 0.335  Epoch:6 Iteration:600\n",
      "Loss: 0.456  Epoch:6 Iteration:700\n",
      "Loss: 0.337  Epoch:6 Iteration:800\n",
      "Loss: 0.334  Epoch:6 Iteration:900\n",
      "Loss: 0.419  Epoch:7 Iteration:0\n",
      "Loss: 0.305  Epoch:7 Iteration:100\n",
      "Loss: 0.488  Epoch:7 Iteration:200\n",
      "Loss: 0.344  Epoch:7 Iteration:300\n",
      "Loss: 0.387  Epoch:7 Iteration:400\n",
      "Loss: 0.259  Epoch:7 Iteration:500\n",
      "Loss: 0.473  Epoch:7 Iteration:600\n",
      "Loss: 0.504  Epoch:7 Iteration:700\n",
      "Loss: 0.354  Epoch:7 Iteration:800\n",
      "Loss: 0.320  Epoch:7 Iteration:900\n",
      "Loss: 0.273  Epoch:8 Iteration:0\n",
      "Loss: 0.398  Epoch:8 Iteration:100\n",
      "Loss: 0.382  Epoch:8 Iteration:200\n",
      "Loss: 0.304  Epoch:8 Iteration:300\n",
      "Loss: 0.478  Epoch:8 Iteration:400\n",
      "Loss: 0.245  Epoch:8 Iteration:500\n",
      "Loss: 0.597  Epoch:8 Iteration:600\n",
      "Loss: 0.513  Epoch:8 Iteration:700\n",
      "Loss: 0.235  Epoch:8 Iteration:800\n",
      "Loss: 0.406  Epoch:8 Iteration:900\n",
      "Loss: 0.272  Epoch:9 Iteration:0\n",
      "Loss: 0.390  Epoch:9 Iteration:100\n",
      "Loss: 0.391  Epoch:9 Iteration:200\n",
      "Loss: 0.543  Epoch:9 Iteration:300\n",
      "Loss: 0.386  Epoch:9 Iteration:400\n",
      "Loss: 0.293  Epoch:9 Iteration:500\n",
      "Loss: 0.334  Epoch:9 Iteration:600\n",
      "Loss: 0.356  Epoch:9 Iteration:700\n",
      "Loss: 0.433  Epoch:9 Iteration:800\n",
      "Loss: 0.479  Epoch:9 Iteration:900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Trainig time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.849</td>\n",
       "      <td>0.863283</td>\n",
       "      <td>94.128565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision  Trainig time\n",
       "0     0.849   0.863283     94.128565"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainedNet, meausured_time  = trainModel(LeNet(), trainLoader)\n",
    "label_true, label_pred = evalNN(trainedNet, testLoader)\n",
    "pd.DataFrame( [{\"Accuracy\":accuracy_score(label_true, label_pred),\n",
    "                \"Precision\":precision_score(label_true, label_pred,average=\"macro\"),\n",
    "                \"Trainig time\":meausured_time}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training resnet with data augemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.303  Epoch:0 Iteration:0\n",
      "Loss: 2.312  Epoch:0 Iteration:100\n",
      "Loss: 2.299  Epoch:0 Iteration:200\n",
      "Loss: 2.297  Epoch:0 Iteration:300\n",
      "Loss: 2.285  Epoch:0 Iteration:400\n",
      "Loss: 2.277  Epoch:0 Iteration:500\n",
      "Loss: 2.247  Epoch:0 Iteration:600\n",
      "Loss: 2.210  Epoch:0 Iteration:700\n",
      "Loss: 2.093  Epoch:0 Iteration:800\n",
      "Loss: 1.759  Epoch:0 Iteration:900\n",
      "Loss: 1.548  Epoch:1 Iteration:0\n",
      "Loss: 1.410  Epoch:1 Iteration:100\n",
      "Loss: 1.440  Epoch:1 Iteration:200\n",
      "Loss: 1.243  Epoch:1 Iteration:300\n",
      "Loss: 1.128  Epoch:1 Iteration:400\n",
      "Loss: 0.895  Epoch:1 Iteration:500\n",
      "Loss: 1.011  Epoch:1 Iteration:600\n",
      "Loss: 0.992  Epoch:1 Iteration:700\n",
      "Loss: 1.032  Epoch:1 Iteration:800\n",
      "Loss: 0.918  Epoch:1 Iteration:900\n",
      "Loss: 0.993  Epoch:2 Iteration:0\n",
      "Loss: 0.801  Epoch:2 Iteration:100\n",
      "Loss: 0.714  Epoch:2 Iteration:200\n",
      "Loss: 0.727  Epoch:2 Iteration:300\n",
      "Loss: 0.874  Epoch:2 Iteration:400\n",
      "Loss: 0.782  Epoch:2 Iteration:500\n",
      "Loss: 0.864  Epoch:2 Iteration:600\n",
      "Loss: 0.702  Epoch:2 Iteration:700\n",
      "Loss: 0.614  Epoch:2 Iteration:800\n",
      "Loss: 0.724  Epoch:2 Iteration:900\n",
      "Loss: 0.750  Epoch:3 Iteration:0\n",
      "Loss: 0.912  Epoch:3 Iteration:100\n",
      "Loss: 0.972  Epoch:3 Iteration:200\n",
      "Loss: 0.927  Epoch:3 Iteration:300\n",
      "Loss: 0.664  Epoch:3 Iteration:400\n",
      "Loss: 0.747  Epoch:3 Iteration:500\n",
      "Loss: 0.808  Epoch:3 Iteration:600\n",
      "Loss: 0.823  Epoch:3 Iteration:700\n",
      "Loss: 0.838  Epoch:3 Iteration:800\n",
      "Loss: 0.485  Epoch:3 Iteration:900\n",
      "Loss: 0.950  Epoch:4 Iteration:0\n",
      "Loss: 0.615  Epoch:4 Iteration:100\n",
      "Loss: 0.571  Epoch:4 Iteration:200\n",
      "Loss: 0.601  Epoch:4 Iteration:300\n",
      "Loss: 0.932  Epoch:4 Iteration:400\n",
      "Loss: 0.697  Epoch:4 Iteration:500\n",
      "Loss: 0.772  Epoch:4 Iteration:600\n",
      "Loss: 0.684  Epoch:4 Iteration:700\n",
      "Loss: 0.600  Epoch:4 Iteration:800\n",
      "Loss: 0.588  Epoch:4 Iteration:900\n",
      "Loss: 0.698  Epoch:5 Iteration:0\n",
      "Loss: 0.710  Epoch:5 Iteration:100\n",
      "Loss: 0.590  Epoch:5 Iteration:200\n",
      "Loss: 0.596  Epoch:5 Iteration:300\n",
      "Loss: 0.610  Epoch:5 Iteration:400\n",
      "Loss: 0.616  Epoch:5 Iteration:500\n",
      "Loss: 0.630  Epoch:5 Iteration:600\n",
      "Loss: 0.636  Epoch:5 Iteration:700\n",
      "Loss: 0.411  Epoch:5 Iteration:800\n",
      "Loss: 0.463  Epoch:5 Iteration:900\n",
      "Loss: 0.507  Epoch:6 Iteration:0\n",
      "Loss: 0.555  Epoch:6 Iteration:100\n",
      "Loss: 0.661  Epoch:6 Iteration:200\n",
      "Loss: 0.897  Epoch:6 Iteration:300\n",
      "Loss: 0.558  Epoch:6 Iteration:400\n",
      "Loss: 0.552  Epoch:6 Iteration:500\n",
      "Loss: 0.550  Epoch:6 Iteration:600\n",
      "Loss: 0.488  Epoch:6 Iteration:700\n",
      "Loss: 0.528  Epoch:6 Iteration:800\n",
      "Loss: 0.602  Epoch:6 Iteration:900\n",
      "Loss: 0.900  Epoch:7 Iteration:0\n",
      "Loss: 0.547  Epoch:7 Iteration:100\n",
      "Loss: 0.624  Epoch:7 Iteration:200\n",
      "Loss: 0.608  Epoch:7 Iteration:300\n",
      "Loss: 0.573  Epoch:7 Iteration:400\n",
      "Loss: 0.768  Epoch:7 Iteration:500\n",
      "Loss: 0.749  Epoch:7 Iteration:600\n",
      "Loss: 0.596  Epoch:7 Iteration:700\n",
      "Loss: 0.723  Epoch:7 Iteration:800\n",
      "Loss: 0.839  Epoch:7 Iteration:900\n",
      "Loss: 0.626  Epoch:8 Iteration:0\n",
      "Loss: 0.575  Epoch:8 Iteration:100\n",
      "Loss: 0.530  Epoch:8 Iteration:200\n",
      "Loss: 0.432  Epoch:8 Iteration:300\n",
      "Loss: 0.456  Epoch:8 Iteration:400\n",
      "Loss: 0.513  Epoch:8 Iteration:500\n",
      "Loss: 0.328  Epoch:8 Iteration:600\n",
      "Loss: 0.597  Epoch:8 Iteration:700\n",
      "Loss: 0.463  Epoch:8 Iteration:800\n",
      "Loss: 0.556  Epoch:8 Iteration:900\n",
      "Loss: 0.665  Epoch:9 Iteration:0\n",
      "Loss: 0.668  Epoch:9 Iteration:100\n",
      "Loss: 0.401  Epoch:9 Iteration:200\n",
      "Loss: 0.532  Epoch:9 Iteration:300\n",
      "Loss: 0.533  Epoch:9 Iteration:400\n",
      "Loss: 0.687  Epoch:9 Iteration:500\n",
      "Loss: 0.664  Epoch:9 Iteration:600\n",
      "Loss: 0.554  Epoch:9 Iteration:700\n",
      "Loss: 0.486  Epoch:9 Iteration:800\n",
      "Loss: 0.583  Epoch:9 Iteration:900\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Trainig time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.798838</td>\n",
       "      <td>128.270577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision  Trainig time\n",
       "0    0.7987   0.798838    128.270577"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainedNetAug, meausured_timeAug  = trainModel(LeNet(), trainLoaderAug)\n",
    "label_true, label_pred = evalNN(trainedNetAug, testLoader)\n",
    "pd.DataFrame( [{\"Accuracy\":accuracy_score(label_true, label_pred),\n",
    "                \"Precision\":precision_score(label_true, label_pred,average=\"macro\"),\n",
    "                \"Trainig time\":meausured_timeAug}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 layer Lenet with class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_MoreConv(nn.Module):\n",
    "  def __init__(self):\n",
    "      super(LeNet_MoreConv, self).__init__()\n",
    "      self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "      self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "      self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "      self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "      self.conv3 = nn.Conv2d(16, 32, kernel_size=3)  # Added third convolutional layer\n",
    "      self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "      self.fc1 = nn.Linear(32 * 2 * 2, 120)  # Adjusted input size for fc1\n",
    "      self.fc2 = nn.Linear(120, 84)\n",
    "      self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = self.pool1(nn.functional.relu(self.conv1(x)))\n",
    "      x = self.pool2(nn.functional.relu(self.conv2(x)))\n",
    "      x = self.pool3(nn.functional.relu(self.conv3(x)))  # Added third pooling layer\n",
    "      x = x.view(-1, 32 * 2 * 2)  # Reshaped for fc1\n",
    "      x = nn.functional.relu(self.fc1(x))\n",
    "      x = nn.functional.relu(self.fc2(x))\n",
    "      x = self.fc3(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-layered lenet model without data augementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (16) to match target batch_size (64).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainedNet, meausured_time  \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLeNet3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainLoader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m label_true, label_pred \u001b[38;5;241m=\u001b[39m evalNN(trainedNet, testLoader)\n\u001b[0;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame( [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m:accuracy_score(label_true, label_pred),\n\u001b[0;32m      4\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m\"\u001b[39m:precision_score(label_true, label_pred,average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      5\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainig time\u001b[39m\u001b[38;5;124m\"\u001b[39m:meausured_time}])\n",
      "Cell \u001b[1;32mIn[19], line 15\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(nnModel, trainLoader, optimizerMethod, lossFunction, lRate, n_epochs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[0;32m     14\u001b[0m output \u001b[38;5;241m=\u001b[39m nnModel(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mlossFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Adam\\Documents\\TUWien\\ML\\EX3\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Adam\\Documents\\TUWien\\ML\\EX3\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Adam\\Documents\\TUWien\\ML\\EX3\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Adam\\Documents\\TUWien\\ML\\EX3\\venv\\lib\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected input batch_size (16) to match target batch_size (64)."
     ]
    }
   ],
   "source": [
    "trainedNet, meausured_time  = trainModel(LeNet3(), trainLoader)\n",
    "label_true, label_pred = evalNN(trainedNet, testLoader)\n",
    "pd.DataFrame( [{\"Accuracy\":accuracy_score(label_true, label_pred),\n",
    "                \"Precision\":precision_score(label_true, label_pred,average=\"macro\"),\n",
    "                \"Trainig time\":meausured_time}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-layered lenet model with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (4 x 4). Kernel size: (5 x 5). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainedNet, meausured_time  \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLeNet3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainLoaderAug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m label_true, label_pred \u001b[38;5;241m=\u001b[39m evalNN(trainedNet, testLoader)\n\u001b[0;32m      3\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame( [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m:accuracy_score(label_true, label_pred),\n\u001b[0;32m      4\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m\"\u001b[39m:precision_score(label_true, label_pred,average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      5\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainig time\u001b[39m\u001b[38;5;124m\"\u001b[39m:meausured_time}])\n",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(nnModel, trainLoader, optimizerMethod, lossFunction, lRate, n_epochs)\u001b[0m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnnModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m lossFunction(output, labels)\n\u001b[0;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Adam\\Documents\\TUWien\\ML\\EX3\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Adam\\Documents\\TUWien\\ML\\EX3\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m, in \u001b[0;36mLeNet3.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)))\n\u001b[0;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[1;32m---> 15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     16\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n",
      "File \u001b[1;32mc:\\Users\\Adam\\Documents\\TUWien\\ML\\EX3\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Adam\\Documents\\TUWien\\ML\\EX3\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Adam\\Documents\\TUWien\\ML\\EX3\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Adam\\Documents\\TUWien\\ML\\EX3\\venv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (4 x 4). Kernel size: (5 x 5). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "trainedNet, meausured_time  = trainModel(LeNet3(), trainLoaderAug)\n",
    "label_true, label_pred = evalNN(trainedNet, testLoader)\n",
    "pd.DataFrame( [{\"Accuracy\":accuracy_score(label_true, label_pred),\n",
    "                \"Precision\":precision_score(label_true, label_pred,average=\"macro\"),\n",
    "                \"Trainig time\":meausured_time}])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
